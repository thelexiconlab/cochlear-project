{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a column of NH and CI groupings in findings file. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{211: 'CI', 234: 'CI', 300: 'CI', 308: 'CI', 310: 'CI', 312: 'CI', 320: 'CI', 329: 'CI', 335: 'CI', 338: 'CI', 344: 'CI', 390: 'CI', 450: 'CI', 452: 'CI', 483: 'CI', 520: 'CI', 544: 'CI', 556: 'CI', 558: 'CI', 563: 'CI', 570: 'CI', 587: 'CI', 672: 'NH', 673: 'NH', 674: 'NH', 681: 'NH', 698: 'NH', 702: 'NH', 707: 'NH', 711: 'NH', 715: 'NH', 720: 'NH', 722: 'NH', 724: 'NH', 726: 'NH', 730: 'NH', 744: 'NH', 753: 'NH', 754: 'NH', 759: 'NH', 764: 'NH', 767: 'NH', 781: 'CI', 721: 'NH', 657: 'NH', 666: 'NH', 671: 'NH', 686: 'NH', 691: 'NH', 693: 'NH', 697: 'NH', 663: 'NH', 678: 'NH', 498: 'CI', 539: 'CI', 340: 'CI', 436: 'CI', 401: 'CI', 315: 'CI', 159: 'CI'}\n"
     ]
    }
   ],
   "source": [
    "#group_dict for a dictionary with participant id as key and grouping as values \n",
    "participant_demographic = pd.read_csv(\"Raw Data/latest_demo.csv\")\n",
    "participant_demographic\n",
    "\n",
    "ID = participant_demographic[\"ID\"].tolist()\n",
    "Group = participant_demographic[\"Group\"].tolist()\n",
    "group_dict = dict(zip(ID, Group))\n",
    "\n",
    "print(group_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling out the first chart (individual_descriptive_stats.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' adding group column into the csv file'''\n",
    "w2v_ind_stats = pd.read_csv(\"50_dim_results/word2vec_forager_results/individual_descriptive_stats.csv\")\n",
    "s2v_ind_stats = pd.read_csv(\"50_dim_results/speech2vec_forager_results/individual_descriptive_stats.csv\")\n",
    "\n",
    "#get the list of subjects and create a new list for their groupings \n",
    "#word2vec first \n",
    "w2v_subjects = w2v_ind_stats[\"Subject\"].tolist()\n",
    "w2v_groupings = [] \n",
    "\n",
    "for index, row in w2v_ind_stats.iterrows(): \n",
    "    w2v_groupings += [group_dict[int(row['Subject'][4:])]]\n",
    "\n",
    "\n",
    "\n",
    "#speech2vec second\n",
    "s2v_subjects = s2v_ind_stats[\"Subject\"].tolist()\n",
    "s2v_groupings = []\n",
    "for index, row in s2v_ind_stats.iterrows(): \n",
    "    s2v_groupings += [group_dict[int(row['Subject'][4:])]]\n",
    "\n",
    "\n",
    "\n",
    "w2v_ind_stats['Group'] = w2v_groupings\n",
    "s2v_ind_stats['Group'] = s2v_groupings\n",
    "\n",
    "w2v_ind_stats.to_csv(\"300_dim_results/word2vec_forager_results/individual_descriptive_stats.csv\", index = False)\n",
    "s2v_ind_stats.to_csv(\"300_dim_results/speech2vec_forager_results/individual_descriptive_stats.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V NH\n",
      "Semantic_Similarity_mean         0.567587\n",
      "Semantic_Similarity_std          0.176255\n",
      "Frequency_Value_mean             6.424026\n",
      "Frequency_Value_std              0.630294\n",
      "Phonological_Similarity_mean     0.258252\n",
      "Phonological_Similarity_std      0.150603\n",
      "#_of_Items                      21.666667\n",
      "Number_of_Switches               5.466667\n",
      "Cluster_Size_mean                3.458003\n",
      "Cluster_Size_std                 1.218737\n",
      "dtype: float64\n",
      "------------------------------------------------\n",
      "W2V CI\n",
      "Semantic_Similarity_mean         0.594544\n",
      "Semantic_Similarity_std          0.161104\n",
      "Frequency_Value_mean             6.500211\n",
      "Frequency_Value_std              0.644542\n",
      "Phonological_Similarity_mean     0.254685\n",
      "Phonological_Similarity_std      0.133143\n",
      "#_of_Items                      18.800000\n",
      "Number_of_Switches               4.800000\n",
      "Cluster_Size_mean                3.347385\n",
      "Cluster_Size_std                 1.117480\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''W2V ind stats '''\n",
    "\n",
    "#Groupby the two groups of NH and CI \n",
    "\n",
    "# w2v_group.first()\n",
    "w2v_group = w2v_ind_stats.groupby(\"Group\")\n",
    "\n",
    "''' w2v NH'''\n",
    "w2v_NH = w2v_group.get_group(\"NH\")\n",
    "print(\"W2V NH\")\n",
    "print(w2v_NH.aggregate(\"mean\"))\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "''' w2v CI'''\n",
    "w2v_CI = w2v_group.get_group(\"CI\")\n",
    "\n",
    "print(\"W2V CI\")\n",
    "print(w2v_CI.aggregate(\"mean\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2V NH\n",
      "Semantic_Similarity_mean         0.555870\n",
      "Semantic_Similarity_std          0.166626\n",
      "Frequency_Value_mean             6.424026\n",
      "Frequency_Value_std              0.630294\n",
      "Phonological_Similarity_mean     0.258252\n",
      "Phonological_Similarity_std      0.150603\n",
      "#_of_Items                      21.666667\n",
      "Number_of_Switches               5.733333\n",
      "Cluster_Size_mean                3.265463\n",
      "Cluster_Size_std                 1.175125\n",
      "dtype: float64\n",
      "------------------------------------------------\n",
      "S2V CI\n",
      "Semantic_Similarity_mean         0.584827\n",
      "Semantic_Similarity_std          0.155911\n",
      "Frequency_Value_mean             6.500211\n",
      "Frequency_Value_std              0.644542\n",
      "Phonological_Similarity_mean     0.254685\n",
      "Phonological_Similarity_std      0.133143\n",
      "#_of_Items                      18.800000\n",
      "Number_of_Switches               4.933333\n",
      "Cluster_Size_mean                3.270244\n",
      "Cluster_Size_std                 1.074914\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''S2V ind stats '''\n",
    "\n",
    "#Groupby the two groups of NH and CI \n",
    "\n",
    "s2v_group = s2v_ind_stats.groupby(\"Group\")\n",
    "\n",
    "''' s2v NH'''\n",
    "s2v_NH = s2v_group.get_group(\"NH\")\n",
    "\n",
    "print(\"S2V NH\")\n",
    "print(s2v_NH.aggregate(\"mean\"))\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "''' s2v CI'''\n",
    "s2v_CI = s2v_group.get_group(\"CI\")\n",
    "\n",
    "print(\"S2V CI\")\n",
    "print(s2v_CI.aggregate(\"mean\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIlling out the second chart (model_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' adding group column into the csv file'''\n",
    "w2v_model_results = pd.read_csv(\"300_dim_results/word2vec_forager_results/model_results.csv\")\n",
    "s2v_model_results = pd.read_csv(\"300_dim_results/speech2vec_forager_results/model_results.csv\")\n",
    "\n",
    "#get the list of subjects and create a new list for their groupings \n",
    "#word2vec first \n",
    "w2v_subjects = w2v_model_results[\"Subject\"].tolist()\n",
    "w2v_groupings = [] \n",
    "\n",
    "for index, row in w2v_model_results.iterrows(): \n",
    "    w2v_groupings += [group_dict[int(row['Subject'][4:])]]\n",
    "\n",
    "\n",
    "\n",
    "#speech2vec second\n",
    "s2v_subjects = s2v_model_results[\"Subject\"].tolist()\n",
    "s2v_groupings = []\n",
    "for index, row in s2v_model_results.iterrows(): \n",
    "    s2v_groupings += [group_dict[int(row['Subject'][4:])]]\n",
    "\n",
    "\n",
    "\n",
    "w2v_model_results['Group'] = w2v_groupings\n",
    "s2v_model_results['Group'] = s2v_groupings\n",
    "\n",
    "w2v_model_results.to_csv(\"300_dim_results/word2vec_forager_results/model_results.csv\", index = False)\n",
    "s2v_model_results.to_csv(\"300_dim_results/speech2vec_forager_results/model_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v CI static mean\n",
      "Beta_Frequency                        8.946578\n",
      "Beta_Semantic                         3.050690\n",
      "Beta_Phonological                          NaN\n",
      "Negative_Log_Likelihood_Optimized    99.914927\n",
      "dtype: float64\n",
      "\n",
      "w2v CI static sum\n",
      "Subject                              SGO-159SIU-211SIZ-390SKE-234SMK-401SNI-300SNR-...\n",
      "Model                                forage_staticforage_staticforage_staticforage_...\n",
      "Beta_Frequency                                                               268.39734\n",
      "Beta_Semantic                                                                91.520714\n",
      "Beta_Phonological                                                                  0.0\n",
      "Negative_Log_Likelihood_Optimized                                          2997.447804\n",
      "Group                                CICICICICICICICICICICICICICICICICICICICICICICI...\n",
      "dtype: object\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''W2V model stats '''\n",
    "\n",
    "#Groupby the two groups of NH and CI \n",
    "\n",
    "w2v_group = w2v_model_results.groupby([\"Group\", \"Model\"])\n",
    "# print(w2v_group.count())\n",
    "\n",
    "# '''w2v NH dynamic simdrop'''\n",
    "# w2v_NH_dynamic = w2v_group.get_group(('NH', 'forage_dynamic_simdrop'))\n",
    "# print(\"w2v NH dynamic mean\")\n",
    "# print(w2v_NH_dynamic.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"w2v NH dynamic sum\")\n",
    "# print(w2v_NH_dynamic.aggregate(\"sum\"))\n",
    "# print(\"--------------------------------------------------\")\n",
    "\n",
    "# '''w2v NH static'''\n",
    "# w2v_NH_static = w2v_group.get_group(('NH', 'forage_static'))\n",
    "# print(\"w2v NH static mean\")\n",
    "# print(w2v_NH_static.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"w2v NH static sum\")\n",
    "# print(w2v_NH_static.aggregate(\"sum\"))\n",
    "# print(\"--------------------------------------------------------\")\n",
    "\n",
    "# '''w2v CI dynamic simdrop'''\n",
    "# w2v_CI_dynamic = w2v_group.get_group(('CI', 'forage_dynamic_simdrop'))\n",
    "# print(\"w2v CI dynamic mean\")\n",
    "# print(w2v_CI_dynamic.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"w2v CI dynamic sum\")\n",
    "# print(w2v_CI_dynamic.aggregate(\"sum\"))\n",
    "# print(\"------------------------------------------------\")\n",
    "\n",
    "'''w2v CI static'''\n",
    "w2v_CI_static = w2v_group.get_group(('CI', 'forage_static'))\n",
    "print(\"w2v CI static mean\")\n",
    "print(w2v_CI_static.aggregate('mean'))\n",
    "print()\n",
    "print(\"w2v CI static sum\")\n",
    "print(w2v_CI_static.aggregate(\"sum\"))\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2v CI static mean\n",
      "Beta_Frequency                        9.104746\n",
      "Beta_Semantic                         3.165820\n",
      "Beta_Phonological                          NaN\n",
      "Negative_Log_Likelihood_Optimized    99.436761\n",
      "dtype: float64\n",
      "\n",
      "s2v CI static sum\n",
      "Subject                              SGO-159SIU-211SIZ-390SKE-234SMK-401SNI-300SNR-...\n",
      "Model                                forage_staticforage_staticforage_staticforage_...\n",
      "Beta_Frequency                                                              273.142367\n",
      "Beta_Semantic                                                                94.974593\n",
      "Beta_Phonological                                                                  0.0\n",
      "Negative_Log_Likelihood_Optimized                                          2983.102818\n",
      "Group                                CICICICICICICICICICICICICICICICICICICICICICICI...\n",
      "dtype: object\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''S2V model results '''\n",
    "\n",
    "#Groupby the two groups of NH and CI \n",
    "\n",
    "s2v_group = s2v_model_results.groupby([\"Group\", \"Model\"])\n",
    "# print(s2v_group.count())\n",
    "\n",
    "# '''s2v NH dynamic simdrop'''\n",
    "# s2v_NH_dynamic = s2v_group.get_group(('NH', 'forage_dynamic_simdrop'))\n",
    "# print(\"s2v NH dynamic mean\")\n",
    "# print(s2v_NH_dynamic.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"s2v NH dynamic sum\")\n",
    "# print(s2v_NH_dynamic.aggregate(\"sum\"))\n",
    "# print(\"--------------------------------------------------\")\n",
    "\n",
    "# '''s2v NH static'''\n",
    "# s2v_NH_static = s2v_group.get_group(('NH', 'forage_static'))\n",
    "# print(\"s2v NH static mean\")\n",
    "# print(s2v_NH_static.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"s2v NH static sum\")\n",
    "# print(s2v_NH_static.aggregate(\"sum\"))\n",
    "# print(\"--------------------------------------------------------\")\n",
    "\n",
    "# '''s2v CI dynamic simdrop'''\n",
    "# s2v_CI_dynamic = s2v_group.get_group(('CI', 'forage_dynamic_simdrop'))\n",
    "# print(\"s2v CI dynamic mean\")\n",
    "# print(s2v_CI_dynamic.aggregate('mean'))\n",
    "# print()\n",
    "# print(\"s2v CI dynamic sum\")\n",
    "# print(s2v_CI_dynamic.aggregate(\"sum\"))\n",
    "# print(\"------------------------------------------------\")\n",
    "\n",
    "'''s2v CI static'''\n",
    "s2v_CI_static = s2v_group.get_group(('CI', 'forage_static'))\n",
    "print(\"s2v CI static mean\")\n",
    "print(s2v_CI_static.aggregate('mean'))\n",
    "print()\n",
    "print(\"s2v CI static sum\")\n",
    "print(s2v_CI_static.aggregate(\"sum\"))\n",
    "print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a individual_descriptive dataframe and model_results dataframe with 50, 100, 200, 300 embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Individual_descriptive dataframe first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Individidual_descriptive dataframe => dimension_switch_results \n",
    "dimension_switch_results = pd.DataFrame(columns=[\"dimension\", \"language_model\", \"group\", \"mean_num_switches\", \"mean_cluster_size\", \"mean_semantic_similarity\", \"mean_phonological_similarity\", \"mean_frequency\"])\n",
    "\n",
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "language_models = [\"word2vec\", \"speech2vec\"]\n",
    "groups = [\"NH\", \"CI\"]\n",
    "stats = [\"mean_num_switches\", \"mean_cluster_size\", \"mean_semantic_similarity\", \"mean_phonological_similarity\", \"mean_frequency\"]\n",
    "stats_label = [\"Number_of_Switches\", \"Cluster_Size_mean\", \"Semantic_Similarity_mean\", \"Phonological_Similarity_mean\", \"Frequency_Value_mean\"]\n",
    "\n",
    "dimension_switch_results\n",
    "\n",
    "dim_path = \"_dim_results/\"\n",
    "results_path = \"_forager_results/individual_descriptive_stats.csv\"\n",
    "\n",
    "rows = []\n",
    "for dimension in dimensions: \n",
    "    for language in language_models: \n",
    "        # read individual_descriptive_stats.csv \n",
    "        path = dimension + dim_path + language + results_path\n",
    "        data = pd.read_csv(path)\n",
    "        language_group = data.groupby(\"Group\")\n",
    "        for group in groups: \n",
    "            row = [dimension, language, group]\n",
    "            test_group = language_group.get_group(group)\n",
    "            i = 0 \n",
    "            while i < len(stats): \n",
    "                row += [test_group[stats_label[i]].mean()]\n",
    "                i += 1\n",
    "            rows += [row]\n",
    "                \n",
    "\n",
    "for line in rows: \n",
    "    dimension_switch_results.loc[len(dimension_switch_results)] = line \n",
    "    \n",
    "dimension_switch_results.to_csv(\"Findings/dimension_switch_results.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dimensional_model_results.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50', 'word2vec', 'Dynamic/Simdrop', 'NH', 3488.0386209538824, 3.919814976655118, 8.01366929775946, 'n/a']\n"
     ]
    }
   ],
   "source": [
    "#model_results dataframe => dimension_model_results \n",
    "dimension_model_results = pd.DataFrame(columns=[\"dimension\", \"language_model\", \"model\", \"group\", \"sum_NLL\", \"mean_beta_semantic\", \"mean_beta_freq\", \"mean_beta_phon\"])\n",
    "\n",
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "model = [\"Dynamic/Simdrop\", \"Static/None\"]\n",
    "model_label = [\"forage_dynamic_simdrop\", \"forage_static\"]\n",
    "language_models = [\"word2vec\", \"speech2vec\"]\n",
    "groups = [\"NH\", \"CI\"]\n",
    "stats = [\"sum_NLL\", \"mean_beta_semantic\", \"mean_beta_freq\", \"mean_beta_phon\"]\n",
    "stats_label = [\"Negative_Log_Likelihood_Optimized\", \"Beta_Semantic\", \"Beta_Frequency\", \"Beta_Phonological\"]\n",
    "\n",
    "dim_path = \"_dim_results/\"\n",
    "results_path = \"_forager_results/model_results.csv\"\n",
    "\n",
    "rows = []\n",
    "for dimension in dimensions: \n",
    "    for language in language_models: \n",
    "            # read model_results.csv\n",
    "            path = dimension + dim_path + language + results_path\n",
    "            data = pd.read_csv(path)\n",
    "            data_groups = data.groupby([\"Group\", \"Model\"])\n",
    "            \n",
    "            i = 0 \n",
    "            while i < len(model): \n",
    "                for group in groups: \n",
    "                    row = [dimension, language, model[i], group]\n",
    "                    test_data = data_groups.get_group((group, model_label[i]))\n",
    "\n",
    "                    j = 0 \n",
    "                    while j < len(stats): \n",
    "                        if j == 0:\n",
    "                            row += [test_data[stats_label[j]].sum()]\n",
    "                        elif j == len(stats) - 1: \n",
    "                            row += [\"n/a\"]\n",
    "                        else: \n",
    "                            row += [test_data[stats_label[j]].mean()]\n",
    "                        j += 1 \n",
    "                    rows += [row]\n",
    "                i += 1 \n",
    "            \n",
    "print(rows[0])\n",
    "for line in rows: \n",
    "    dimension_model_results.loc[len(dimension_model_results)] = line \n",
    "dimension_model_results\n",
    "dimension_model_results.to_csv(\"Findings/dimension_model_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
