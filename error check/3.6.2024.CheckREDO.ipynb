{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check phonological matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/md5b66vn4l39df_j063nqlp00000gn/T/ipykernel_97777/180603866.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import scipy\n",
    "from functools import lru_cache\n",
    "from itertools import product as iterprod\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class phonology_funcs:\n",
    "    '''\n",
    "        Description: \n",
    "            This class contains functions to generate phonemes from a list of words and create a phonological similarity matrix.\n",
    "            Code has been adapted from the following link: https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
    "        Functions:\n",
    "            (1) load_arpabet(): loads and returns the arpabet dictionary from the NLTK CMU dictionary\n",
    "            (2) wordbreak(s, arpabet): takes in a word (str) and an arpabet dictionary and returns a list of phonemes\n",
    "            (3) normalized_edit_distance(w1, w2): takes in two strings (w1, w2) and returns the normalized edit distance between them\n",
    "            (3) create_phonological_matrix: takes in a list of labels (size N) and returns a phonological similarity matrix (NxN np.array)\n",
    "    '''\n",
    "    @lru_cache()\n",
    "    def wordbreak(s):\n",
    "        '''\n",
    "            Description:\n",
    "                Takes in a word (str) and an arpabet dictionary and returns a list of phonemes\n",
    "            Args:\n",
    "                (1) s (str): string to be broken into phonemes\n",
    "            Returns:\n",
    "                (1) phonemes (list, size: variable): list of phonemes in s \n",
    "        '''\n",
    "        try:\n",
    "            arpabet = nltk.corpus.cmudict.dict()\n",
    "        except LookupError:\n",
    "            nltk.download('cmudict')\n",
    "            arpabet = nltk.corpus.cmudict.dict()\n",
    "                \n",
    "        s = s.lower()\n",
    "        if s in arpabet:\n",
    "            return arpabet[s]\n",
    "        middle = len(s)/2\n",
    "        partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
    "        for i in partition:\n",
    "            pre, suf = (s[:i], s[i:])\n",
    "            if pre in arpabet and phonology_funcs.wordbreak(suf) is not None:\n",
    "                return [x+y for x,y in iterprod(arpabet[pre], phonology_funcs.wordbreak(suf))]\n",
    "        return None\n",
    "\n",
    "    def normalized_edit_distance(w1, w2):\n",
    "        '''\n",
    "            Description: \n",
    "                Takes in two strings (w1, w2) and returns the normalized edit distance between them\n",
    "            Args:\n",
    "                (1) w1 (str): first word\n",
    "                (2) w2 (str): second word\n",
    "            Returns:\n",
    "                (1) normalized_edit_distance (float): normalized edit distance between w1 and w2\n",
    "        '''\n",
    "        return round(1-nltk.edit_distance(w1,w2)/(max(len(w1), len(w2))),4)\n",
    "\n",
    "    def phonological_similarity(word1, word2): \n",
    "        phon_sim = phonology_funcs.normalized_edit_distance(phonology_funcs.wordbreak(word1)[0], phonology_funcs.wordbreak(word2)[0])\n",
    "        return phon_sim\n",
    "\n",
    "\n",
    "def semantic_similarity(word1, word2, path_to_embeddings): \n",
    "    embeddings = pd.read_csv(path_to_embeddings)\n",
    "    \n",
    "    word1_embedding = embeddings[word1].T\n",
    "    word2_embedding = embeddings[word2].T\n",
    "    \n",
    "    similarity = 1 - scipy.spatial.distance.cosine(word1_embedding, word2_embedding)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "new_words = pd.read_csv(\"new_vocab.csv\")\n",
    "new_words = new_words['Word'].tolist()\n",
    "print(len(new_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.1429,\n",
       " 0.125,\n",
       " 0.2857,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.3333,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2857,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.1429,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.1111,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.1429,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.25,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.1111,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.125,\n",
       " 0.1667,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.2,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.3333,\n",
       " 0.2,\n",
       " 0.3333,\n",
       " 0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1429,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1667,\n",
       " 0.1667,\n",
       " 0.2857,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phon_sample = [] \n",
    "for word in new_words: \n",
    "    phon_output = phonology_funcs.phonological_similarity('adder', word)\n",
    "    phon_sample.append(phon_output)\n",
    "\n",
    "phon_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "words_gotten = ['adder', 'african', 'albatross', 'alligator', 'alpaca', 'american', 'anchovy', 'anemone', 'ant', 'antelope', 'ape', 'asian', 'asp', 'ass', 'australian', 'baboon', 'baby', 'badger', 'bantam', 'basilisk', 'bass', 'bat', 'beagle', 'bear', 'beaver', 'bee', 'beetle', 'bird', 'bison', 'bittern', 'blackbird', 'bluebird', 'boa', 'boar', 'booby', 'boxer', 'bruin', 'buck', 'buffalo', 'bug', 'bull', 'bulldog', 'bullfrog', 'bullock', 'bumblebee', 'bunny', 'bunting', 'butterflies', 'butterfly', 'buzzard', 'calf', 'camel', 'cameo', 'canary', 'canine', 'caplin', 'cardinal', 'caribou', 'carp', 'cat', 'caterpillar', 'cattle', 'centipede', 'chaffinch', 'chameleon', 'chamois', 'char', 'chick', 'chickadee', 'chicken', 'chimaera', 'chinook', 'chipmunk', 'clam', 'cobra', 'cochineal', 'cock', 'cockle', 'cod', 'codfish', 'collie', 'colt', 'coney', 'coral', 'cougar', 'courser', 'cow', 'cows', 'coyote', 'crab', 'crane', 'crawfish', 'crayfish', 'cricket', 'crocodile', 'crow', 'cub', 'cuckoo', 'curlew', 'cuttlefish', 'dear', 'deer', 'deerhound', 'devil', 'dodo', 'doe', 'dog', 'dogs', 'dolphin', 'domingo', 'donkey', 'dormouse', 'dory', 'dove', 'dragon', 'drake', 'dromedary', 'duck', 'duckling', 'ducks', 'eagle', 'eel', 'eels', 'eider', 'elephant', 'elk', 'ermine', 'ewe', 'falcon', 'fawn', 'feline', 'ferret', 'filly', 'finch', 'firefly', 'fish', 'fisher', 'flea', 'flies', 'flounder', 'fly', 'flycatcher', 'foal', 'fowl', 'fox', 'foxes', 'foxhound', 'frog', 'fungi', 'gal', 'gamecock', 'gander', 'gar', 'gazelle', 'geese', 'giant', 'gibbon', 'girdle', 'glaucus', 'gnat', 'goat', 'goats', 'goby', 'goldfinch', 'goldfish', 'goose', 'gopher', 'gorilla', 'grasshopper', 'grenadier', 'greyhound', 'grizzly', 'grosbeak', 'grouse', 'grub', 'grunt', 'guanaco', 'guerrilla', 'guinea', 'gull', 'hackney', 'haddock', 'halcyon', 'hare', 'hart', 'hawk', 'hedgehog', 'heifer', 'hen', 'hermit', 'heron', 'herring', 'hippopotamus', 'hog', 'hogs', 'hoopoe', 'horse', 'hound', 'human', 'huntsman', 'husky', 'hydra', 'hyena', 'hyenas', 'ibex', 'insect', 'insects', 'jack', 'jackal', 'jackass', 'jackdaw', 'jaguar', 'jay', 'jellyfish', 'kangaroo', 'kelpie', 'kid', 'killer', 'kingfisher', 'kite', 'kitten', 'kitty', 'lab', 'labrador', 'ladybird', 'ladybug', 'lamb', 'lark', 'larva', 'larvae', 'leech', 'lemming', 'leopard', 'lice', 'linnet', 'lion', 'lioness', 'lions', 'lizard', 'llama', 'loach', 'lobster', 'locust', 'loon', 'louse', 'lynx', 'mackerel', 'maggot', 'magpie', 'maltese', 'mammoth', 'man', 'mare', 'marmot', 'marten', 'mastiff', 'mastodon', 'medusa', 'merlin', 'mice', 'microbe', 'midge', 'mink', 'minnow', 'minx', 'mite', 'moccasin', 'mole', 'mollusk', 'mongoose', 'monitor', 'monkey', 'monkeys', 'monster', 'moose', 'moray', 'mosquito', 'moth', 'moths', 'mouse', 'mule', 'mules', 'mullet', 'muskrat', 'mussel', 'mustang', 'nautilus', 'newt', 'nightingale', 'nuthatch', 'orang', 'oriole', 'oscar', 'ostrich', 'ostriches', 'otter', 'owl', 'ox', 'oxen', 'oyster', 'oysters', 'panther', 'papillon', 'parakeet', 'parrot', 'partridge', 'peacock', 'pegasus', 'pelican', 'penguin', 'perch', 'peregrine', 'person', 'pets', 'pewee', 'pheasant', 'phoenix', 'pig', 'pigeon', 'piggy', 'pike', 'pilgrim', 'plover', 'polar', 'pollock', 'pony', 'poodle', 'porcupine', 'pork', 'porpoise', 'possum', 'poultry', 'prairie', 'primate', 'ptarmigan', 'puffin', 'pug', 'pullet', 'puma', 'pup', 'puppy', 'puss', 'quail', 'rabbit', 'rainbow', 'ram', 'rat', 'rattler', 'rattlesnake', 'raven', 'ray', 'redbird', 'redbreast', 'redtail', 'reindeer', 'reptile', 'rhinoceros', 'roach', 'robin', 'rodents', 'roe', 'rook', 'rooster', 'sable', 'salamander', 'salmon', 'sardine', 'scorpion', 'seal', 'serpent', 'shad', 'shark', 'sheep', 'shellfish', 'shepherd', 'shrew', 'shrimp', 'silkworm', 'skate', 'skunk', 'skylark', 'sloth', 'slug', 'smelt', 'snail', 'snake', 'snapper', 'snipe', 'sow', 'spaniel', 'sparrow', 'spider', 'sponge', 'sprat', 'squab', 'squirrel', 'stag', 'stallion', 'starfish', 'starling', 'steed', 'steer', 'stork', 'sturgeon', 'sunfish', 'swallow', 'swan', 'swift', 'swine', 'tabby', 'tadpole', 'takin', 'tanager', 'tern', 'terrier', 'thoroughbred', 'thrush', 'tick', 'tiger', 'titmouse', 'toad', 'tortoise', 'tortuga', 'triggerfish', 'trotter', 'trout', 'trumpeter', 'tunny', 'turbot', 'turkey', 'turtle', 'unicorn', 'urchin', 'veal', 'vermin', 'viper', 'vulture', 'walrus', 'warbler', 'wasp', 'water', 'waterfowl', 'weasel', 'whale', 'whelp', 'whiff', 'whitefish', 'whiting', 'wildcat', 'winkle', 'wolf', 'wolfhound', 'wolverine', 'wolves', 'woman', 'woodchuck', 'woodcock', 'woodpecker', 'worm', 'wren', 'yak', 'yellowlegs', 'zebra']\n",
    "print(words_gotten == new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
